{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necesseary libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate Datasets Part\n",
    "hotel_2301 = 'Data/HOTEL_2023_01to11/Hotel_data2023/HOT2301.CSV'\n",
    "hotel_2302 = 'Data/HOTEL_2023_01to11/Hotel_data2023/HOT2302.CSV'\n",
    "hotel_2303 = 'Data/HOTEL_2023_01to11/Hotel_data2023/HOT2303.CSV'\n",
    "hotel_2304 = 'Data/HOTEL_2023_01to11/Hotel_data2023/HOT2304.CSV'\n",
    "hotel_2305 = 'Data/HOTEL_2023_01to11/Hotel_data2023/HOT2305.CSV'\n",
    "hotel_2306 = 'Data/HOTEL_2023_01to11/Hotel_data2023/HOT2306.CSV'\n",
    "hotel_2307 = 'Data/HOTEL_2023_01to11/Hotel_data2023/HOT2307.CSV'\n",
    "hotel_2308 = 'Data/HOTEL_2023_01to11/Hotel_data2023/HOT2308.CSV'\n",
    "hotel_2309 = 'Data/HOTEL_2023_01to11/Hotel_data2023/HOT2309.CSV'\n",
    "hotel_2310 = 'Data/HOTEL_2023_01to11/Hotel_data2023/HOT2310.CSV'\n",
    "hotel_2311 = 'Data/HOTEL_2023_01to11/Hotel_data2023/HOT2311.CSV'\n",
    "\n",
    "file_paths_2023 = [hotel_2301, hotel_2302, hotel_2303, hotel_2304,\\\n",
    "              hotel_2305, hotel_2306, hotel_2307, hotel_2308,\\\n",
    "              hotel_2309, hotel_2310, hotel_2311]\n",
    "# append data from Jan 2023 to Nov 2023\n",
    "dfs = []\n",
    "\n",
    "headers = [\n",
    "    \"Taxpayer_Number\", \"Taxpayer_Name\", \"Taxpayer_Address\", \"Taxpayer_City\",\n",
    "    \"Taxpayer_State\",\"Taxpayer_Zip\", \"Taxpayer_County\", \"Taxpayer_Phone\",\n",
    "    \"Location_Number\", \"Location_Name\", \"Location_Address\", \"Location_City\",\n",
    "    \"Location_State\", \"Location_Zip\", \"Location_County\",\"Location_Phone\",\n",
    "    \"Unit_Capacity\", \"Responsibility_Begin_Date_(YYYYMMDD)\",\n",
    "    \"Responsibility_End_Date_(YYYYMMDD)\", \"Obligation_End_Date_(YYYYMMDD)\",\n",
    "    \"Filer_Type\", \"Total_Room_Receipts\", \"Taxable_Receipts\"\n",
    "]\n",
    "\n",
    "# Using for loop to contcatenate monthly dataset into one 2023 dataset\n",
    "for file in file_paths_2023:\n",
    "    try:\n",
    "        df = pd.read_csv(file, names=headers, header=None, encoding='ISO-8859-1')  # or 'latin1' or 'windows-1252'\n",
    "        dfs.append(df)\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# Make sure dataset structure stays align\n",
    "hotel_2023 = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling needed annual tax report\n",
    "hotel_2021_path = 'Data/HOTEL2021/HOTEL2021.CSV'\n",
    "hotel_2022_path = 'Data/HOTEL2022/HOTEL2022.CSV'\n",
    "\n",
    "# Updated has 2021 to 2023\n",
    "file_path_21_to_22= [hotel_2021_path, hotel_2022_path]\n",
    "\n",
    "# Data type specification for zip codes as strings\n",
    "dtype_spec = {'Taxpayer_Zip': str, 'Location_Zip': str}\n",
    "\n",
    "# Function to clean zip codes\n",
    "def clean_zip_code(zip_code):\n",
    "    clean_zip = ''.join(filter(str.isdigit, str(zip_code)))\n",
    "    return clean_zip[:5] if len(clean_zip) >= 5 else None\n",
    "\n",
    "# Concatenate dfs\n",
    "df1s = []\n",
    "for file in file_path_21_to_22:\n",
    "    try:\n",
    "        # Adding low_memory=False parameter\n",
    "        df = pd.read_csv(file, names=headers, header=None, encoding='ISO-8859-1', dtype=dtype_spec, low_memory=False)\n",
    "        # Clean Location_Zip\n",
    "        df['Location_Zip'] = df['Location_Zip'].apply(clean_zip_code)\n",
    "        df = df[df['Location_Zip'].str.isnumeric()]  # Filter only numeric zips\n",
    "        df1s.append(df)\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "hotel_21_to_22 = pd.concat(df1s, ignore_index=True)\n",
    "\n",
    "hotel_21_to_Nov23 = pd.concat([hotel_21_to_22, hotel_2023], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dallas = hotel_21_to_Nov23[hotel_21_to_Nov23['Location_City'].str.contains('DALLAS')]\n",
    "\n",
    "# Keep filtering hotel which still are in the market, delete the ones which has value in Responsibility_End_Date\n",
    "# Filter the DataFrame to keep only rows where the 'Responsibility End Date (YYYYMMDD)' column is an empty string after stripping white spaces\n",
    "Dallas_active_hotels = Dallas[Dallas['Responsibility_End_Date_(YYYYMMDD)'].str.strip() == '']\n",
    "\n",
    "# Overwrite Dallas dataset to keep cleaning\n",
    "Dallas = Dallas_active_hotels\n",
    "\n",
    "unique_payer = len(set(Dallas['Taxpayer_Number']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows based on the specified columns\n",
    "unique_locations = Dallas.drop_duplicates(subset=['Location_Number', 'Location_Name', 'Location_Address','Location_County'])\n",
    "\n",
    "# Reset the index to ensure it starts from 0\n",
    "unique_locations.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add a new column 'Location_ID' with incremental values starting from 1\n",
    "unique_locations['Location_ID'] = range(1, len(unique_locations) + 1)\n",
    "\n",
    "# Get the number of unique locations\n",
    "num_unique_locations = unique_locations.shape[0]\n",
    "\n",
    "# Merge the original Dallas DataFrame with the unique_locations to include the Location_ID\n",
    "Dallas_with_ID = Dallas.merge(unique_locations[['Location_Number', 'Location_Name', 'Location_Address', 'Location_County', 'Location_ID']],\n",
    "                              on=['Location_Number', 'Location_Name', 'Location_Address', 'Location_County'],\n",
    "                              how='left')\n",
    "\n",
    "# Sort dataset by Location_ID and Obligation_End_Date_(YYYYMMDD)\n",
    "Dallas_with_ID_sorted = Dallas_with_ID.sort_values(by=['Location_ID', 'Obligation_End_Date_(YYYYMMDD)'])\n",
    "\n",
    "Dallas_with_ID_sorted.to_csv(\"Dallas_with_ID.csv\",index=False, header=False)\n",
    "\n",
    "# Cleaning Tax Government Data Part is Done, output is Dallas_with_ID dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macs30120",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
